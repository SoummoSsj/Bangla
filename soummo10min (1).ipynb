{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12584511,"sourceType":"datasetVersion","datasetId":7948106}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Step 0: Install necessary libraries (run once)\n!apt-get install -y poppler-utils tesseract-ocr tesseract-ocr-ben\n!pip install pytesseract pdf2image sentence-transformers faiss-cpu transformers --quiet\n\nimport os\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"  # suppress warnings\n\nimport pytesseract\nfrom pdf2image import convert_from_path\nfrom sentence_transformers import SentenceTransformer\nfrom transformers import pipeline\nimport faiss\nimport nltk\nfrom nltk.tokenize import sent_tokenize\nimport numpy as np\nimport unicodedata\n\nnltk.download('punkt')\n\n# Step 1: OCR extraction of Bengali text from PDF pages using Tesseract\npdf_path = \"/kaggle/input/10mins/HSC26-Bangla1st-Paper.pdf\"  # your PDF\n\nprint(\"Starting OCR extraction using Tesseract...\")\npages = convert_from_path(pdf_path, dpi=300)\n\nfull_text = \"\"\nfor i, page in enumerate(pages):\n    text_page = pytesseract.image_to_string(page, lang='ben')\n    print(f\"Extracted page {i + 1} text: {len(text_page)} chars\")\n    full_text += text_page + \"\\n\"\n\n# Normalize unicode\nfull_text = unicodedata.normalize('NFC', full_text)\n\n# Step 2: Sentence tokenization and chunking for retrieval\nsentences = sent_tokenize(full_text)\nchunk_size = 5\nchunks = [' '.join(sentences[i:i + chunk_size]) for i in range(0, len(sentences), chunk_size)]\nprint(f\"Total chunks created: {len(chunks)}\")\n\n# Step 3: Embedding chunks with multilingual model & build FAISS index\nembedding_model = SentenceTransformer(\"paraphrase-multilingual-MiniLM-L12-v2\")\nprint(\"Encoding chunks...\")\nembeddings = embedding_model.encode(chunks, show_progress_bar=True)\n\ndimension = embeddings.shape[1]\nfaiss_index = faiss.IndexFlatL2(dimension)\nfaiss_index.add(np.array(embeddings))\nprint(f\"FAISS index built with {faiss_index.ntotal} chunks\")\n\n# Step 4: Load pretrained QA model supporting Bengali\n# Example: multilingual XLM-Roberta fine-tuned on SQuAD2 (flexible QA)\nqa_model_name = \"deepset/xlm-roberta-large-squad2\"  \nqa_pipeline = pipeline(\"question-answering\", model=qa_model_name, tokenizer=qa_model_name, device=-1)\n\n# Step 5: Query function performing retrieval + QA inference\ndef answer_query_with_qa_model(query, top_k=5):\n    # 5.1 Embed and retrieve top chunks\n    query_embedding = embedding_model.encode([query])\n    distances, indices = faiss_index.search(np.array(query_embedding), top_k)\n    retrieved_chunks = [chunks[idx] for idx in indices[0]]\n\n    # 5.2 Combine retrieved chunks as context for QA\n    context = \" \".join(retrieved_chunks)\n\n    # Debug: Print retrieved chunk indices and snippet (optional)\n    print(f\"Retrieved chunk indices for query: {indices[0].tolist()}\")\n\n    # 5.3 Run QA model on query and retrieved context\n    result = qa_pipeline(question=query, context=context)\n\n    print(f\"Answer found: {result['answer']}\")\n    return result['answer']\n\n# Step 6: Interactive querying\nif __name__ == \"__main__\":\n    print(\"Enter Bengali questions (type 'exit' to quit):\")\n    while True:\n        user_q = input(\"Please enter your question: \").strip()\n        if user_q.lower() == \"exit\":\n            print(\"Exiting...\")\n            break\n        answer_query_with_qa_model(user_q)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-26T17:38:22.584904Z","iopub.execute_input":"2025-07-26T17:38:22.585166Z","iopub.status.idle":"2025-07-26T17:45:32.279059Z","shell.execute_reply.started":"2025-07-26T17:38:22.585121Z","shell.execute_reply":"2025-07-26T17:45:32.278273Z"}},"outputs":[{"name":"stdout","text":"Reading package lists... Done\nBuilding dependency tree... Done\nReading state information... Done\ntesseract-ocr is already the newest version (4.1.1-2.1build1).\ntesseract-ocr-ben is already the newest version (1:4.00~git30-7274cfa-1.1).\npoppler-utils is already the newest version (22.02.0-2ubuntu0.8).\n0 upgraded, 0 newly installed, 0 to remove and 38 not upgraded.\nStarting OCR extraction using Tesseract...\n","output_type":"stream"},{"name":"stderr","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n","output_type":"stream"},{"name":"stdout","text":"Extracted page 1 text: 117 chars\nExtracted page 2 text: 1400 chars\nExtracted page 3 text: 1399 chars\nExtracted page 4 text: 1101 chars\nExtracted page 5 text: 325 chars\nExtracted page 6 text: 2242 chars\nExtracted page 7 text: 2187 chars\nExtracted page 8 text: 2489 chars\nExtracted page 9 text: 2194 chars\nExtracted page 10 text: 1738 chars\nExtracted page 11 text: 2067 chars\nExtracted page 12 text: 2459 chars\nExtracted page 13 text: 2211 chars\nExtracted page 14 text: 2418 chars\nExtracted page 15 text: 2410 chars\nExtracted page 16 text: 1955 chars\nExtracted page 17 text: 1293 chars\nExtracted page 18 text: 1955 chars\nExtracted page 19 text: 1912 chars\nExtracted page 20 text: 1223 chars\nExtracted page 21 text: 2162 chars\nExtracted page 22 text: 1536 chars\nExtracted page 23 text: 1950 chars\nExtracted page 24 text: 1946 chars\nExtracted page 25 text: 1578 chars\nExtracted page 26 text: 1776 chars\nExtracted page 27 text: 1573 chars\nExtracted page 28 text: 1624 chars\nExtracted page 29 text: 1110 chars\nExtracted page 30 text: 1746 chars\nExtracted page 31 text: 2147 chars\nExtracted page 32 text: 1640 chars\nExtracted page 33 text: 1487 chars\nExtracted page 34 text: 1395 chars\nExtracted page 35 text: 1453 chars\nExtracted page 36 text: 1491 chars\nExtracted page 37 text: 1782 chars\nExtracted page 38 text: 1334 chars\nExtracted page 39 text: 1043 chars\nExtracted page 40 text: 848 chars\nExtracted page 41 text: 582 chars\nExtracted page 42 text: 2577 chars\nExtracted page 43 text: 2036 chars\nExtracted page 44 text: 1820 chars\nExtracted page 45 text: 2659 chars\nExtracted page 46 text: 2497 chars\nExtracted page 47 text: 2513 chars\nExtracted page 48 text: 1850 chars\nExtracted page 49 text: 1275 chars\nTotal chunks created: 90\nEncoding chunks...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cb08c9b2ed564c009e59b331193e5f17"}},"metadata":{}},{"name":"stdout","text":"FAISS index built with 90 chunks\n","output_type":"stream"},{"name":"stderr","text":"Some weights of the model checkpoint at deepset/xlm-roberta-large-squad2 were not used when initializing XLMRobertaForQuestionAnswering: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n- This IS expected if you are initializing XLMRobertaForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing XLMRobertaForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nDevice set to use cpu\n","output_type":"stream"},{"name":"stdout","text":"Enter Bengali questions (type 'exit' to quit):\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Please enter your question:  কাকে অনুপমের ভাগ্য দেবতা বলে উল্লেখ করা হয়েছে?\n"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7130f0a9c875424d88c131d71561b41a"}},"metadata":{}},{"name":"stdout","text":"Retrieved chunk indices for query: [65, 22, 38, 13, 31]\nAnswer found:  মামাকে\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Please enter your question:  অনুপমের ভাষায় সুপুরুষ কাকে বলা হয়েছে?\n"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1cbaf82bcc02468db8ac13616229e35d"}},"metadata":{}},{"name":"stdout","text":"Retrieved chunk indices for query: [13, 22, 85, 15, 87]\nAnswer found:  লোকলজ্জা (খ) পিতৃ আদেশ\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Please enter your question:  বিয়ের সময় কল্যাণীর প্রকৃত বয়স কত ছিল?\n"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"051e90dbeefe478e914eed9adb79f1ce"}},"metadata":{}},{"name":"stdout","text":"Retrieved chunk indices for query: [82, 2, 22, 87, 89]\nAnswer found:  পনেরো,\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Please enter your question:  exit\n"},{"name":"stdout","text":"Exiting...\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"if __name__ == \"__main__\":\n    print(\"Enter Bengali questions (type 'exit' to quit):\")\n    while True:\n        user_q = input(\"Please enter your question: \").strip()\n        if user_q.lower() == \"exit\":\n            print(\"Exiting...\")\n            break\n        answer_query_with_qa_model(user_q)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-26T17:55:44.139520Z","iopub.execute_input":"2025-07-26T17:55:44.139790Z"}},"outputs":[{"name":"stdout","text":"Enter Bengali questions (type 'exit' to quit):\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Please enter your question:  অনুপমের ভাষায় সুপুরুষ কাকে বলা হয়েছে?\n"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6c7425a133a845968bf3dec808aad032"}},"metadata":{}},{"name":"stdout","text":"Retrieved chunk indices for query: [13, 22, 85, 15, 87]\nAnswer found:  লোকলজ্জা (খ) পিতৃ আদেশ\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Please enter your question:  সুপুরুষ কাকে বলা হয়েছে?\n"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5654d5932e9b4340ae00aebd6b97595a"}},"metadata":{}},{"name":"stdout","text":"Retrieved chunk indices for query: [8, 4, 21, 1, 57]\nAnswer found:  বর্ণনার\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Please enter your question:  শরৎচন্দ্র চট্টোপাধ্যায়ের উপন্যাসের নাম কী কী?\n"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"14073ba7248747cabfe524ded0a34cf0"}},"metadata":{}},{"name":"stdout","text":"Retrieved chunk indices for query: [21, 1, 22, 56, 15]\nAnswer found:  'অপরিচিতা'\n","output_type":"stream"}],"execution_count":null}]}