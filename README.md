# ğŸ“š Bengali RAG QA System (PDF â OCR â FAISS â mBERT)

This project is a Bengali-English bilingual **Retrieval-Augmented Generation (RAG)** system that answers natural language questions from a scanned textbook PDF. It uses OCR to extract text, semantic chunking + embedding, and FAISS-based vector search to find relevant content, and a multilingual transformer model for answering user questions.

> âœ… Fully local pipeline â€” No paid API needed  
> ğŸ§  Powered by Tesseract OCR, FAISS, and multilingual SBERT + XLM-RoBERTa  
> ğŸŒ Supports both Bangla and English queries

---

## ğŸ”§ Setup Guide

### ğŸ›  Requirements

- Ubuntu or Linux (tested on Kaggle/Colab)
- Python 3.8+
- Tesseract OCR with Bengali support

### ğŸ Install Dependencies

```bash
# Linux packages
!apt-get install -y poppler-utils tesseract-ocr tesseract-ocr-ben

# Python packages
!pip install pytesseract pdf2image sentence-transformers faiss-cpu transformers nltk --quiet
```

---

## ğŸ“ Input PDF

```python
pdf_path = "/kaggle/input/10mins/HSC26-Bangla1st-Paper.pdf"
```

This system was tested on the **HSC26 Bangla 1st Paper** PDF.

---

## ğŸ§° Tools, Libraries & Packages

| Tool/Library | Purpose |
|--------------|---------|
| `pytesseract` | OCR to extract Bangla text from scanned images |
| `pdf2image` | Convert PDF pages into high-resolution images |
| `nltk` | Sentence tokenization |
| `sentence-transformers` | Multilingual embedding of text chunks |
| `faiss-cpu` | Efficient semantic similarity search |
| `transformers` | Multilingual QA model (`xlm-roberta-large-squad2`) |

---

## ğŸ§  System Pipeline

### 1. **OCR Extraction**

```python
text = pytesseract.image_to_string(page, lang='ben')
```

- **Library used:** `pytesseract` with `tesseract-ocr-ben`
- **Why:** Open-source OCR that supports Bengali script well.
- **Formatting Challenges:** Yes, OCR often introduces unwanted line breaks, punctuation errors, and inconsistent character spacing. Unicode normalization helps reduce noise.

---

### 2. **Chunking Strategy**

```python
sentences = sent_tokenize(full_text)
chunks = [' '.join(sentences[i:i + 5]) for i in range(0, len(sentences), 5)]
```

- **Type:** Sentence-based, fixed-size (5 sentences per chunk)
- **Why it works:** Sentence grouping maintains semantic flow while avoiding overly large inputs. It's also resilient to OCR noise and sentence fragments.

---

### 3. **Text Embedding**

```python
embedding_model = SentenceTransformer("paraphrase-multilingual-MiniLM-L12-v2")
```

- **Why this model:**  
  - Lightweight and fast (MiniLM architecture)  
  - Supports **100+ languages** including Bangla  
  - Trained on paraphrase tasks, ideal for semantic similarity  
- **How it works:**  
  Transforms each chunk into a high-dimensional vector encoding its semantic meaning, capturing both syntax and context.

---

### 4. **Vector Similarity Search**

```python
faiss_index = faiss.IndexFlatL2(dimension)
faiss_index.add(np.array(embeddings))
```

- **Comparison Method:** L2 (Euclidean) distance
- **Why FAISS:**  
  - Fast and memory-efficient
  - Scales to thousands of chunks
- **Why it works:**  
  Closest vectors represent most semantically similar chunks to the query.

---

### 5. **Question Answering Inference**

```python
qa_pipeline = pipeline("question-answering", model="deepset/xlm-roberta-large-squad2")
```

- **Why this model:**  
  - Robust multilingual transformer  
  - Fine-tuned on SQuAD2, capable of handling answerable/unanswerable questions  
- **Process:**  
  - Retrieves top-k chunks  
  - Concatenates them as QA context  
  - Uses transformer to extract answer span

---

## ğŸ’¬ Sample Queries & Outputs

| Query (Bangla)                          | Output                                      |
|----------------------------------------|---------------------------------------------|
| `à¦•à¦¾à¦•à§‡ à¦…à¦¨à§à¦ªà¦®à§‡à¦° à¦­à¦¾à¦—à§à¦¯ à¦¦à§‡à¦¬à¦¤à¦¾ à¦¬à¦²à§‡ à¦‰à¦²à§à¦²à§‡à¦– à¦•à¦°à¦¾ à¦¹à¦¯à¦¼à§‡à¦›à§‡?`                 | `à¦®à¦¾à¦®à¦¾à¦•à§‡`                        |
| ` à¦¬à¦¿à¦¯à¦¼à§‡à¦° à¦¸à¦®à¦¯à¦¼ à¦•à¦²à§à¦¯à¦¾à¦£à§€à¦° à¦ªà§à¦°à¦•à§ƒà¦¤ à¦¬à¦¯à¦¼à¦¸ à¦•à¦¤ à¦›à¦¿à¦²?`         | `à¦ªà¦¨à§‡à¦°à§‹`                                     |


---

## ğŸ§ª Evaluation (Planned but Not Implemented)

### Metrics (Optional for Future Implementation)

| Metric     | Description |
|------------|-------------|
| EM (Exact Match) | Checks if model output exactly matches the ground truth |
| F1 Score   | Token-level overlap between prediction and ground truth |
| Top-k Retrieval Accuracy | Whether relevant chunk was among top-k |

---

## ğŸ“¡ API Documentation (Optional)

```python
def answer_query_with_qa_model(query: str, top_k: int = 5) -> str:
    ...
    return result['answer']
```

---

## â“ Methodological Q&A

See full answers in the markdown above (OCR choice, chunking strategy, embedding model, retrieval design, evaluation reasoning, etc.)

---

## ğŸ“Œ Future Work

- [ ] Add mT5 or IndicBERT for better Bangla performance
- [ ] Implement evaluation metrics (F1, EM)
- [ ] Deploy with Gradio or Streamlit UI
- [ ] Extend to more textbooks or subjects

---

## ğŸ“œ License

MIT License. Not affiliated with Bangladesh NCTB or any publisher.
